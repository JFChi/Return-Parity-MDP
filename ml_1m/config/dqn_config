[META]
ALG = DQN_DEBUG
ACTION_DIM = 50
REWARD_DIM = 20
STATISTIC_DIM = 9
MAX_TRAINING_STEP = 400
DISCOUNT_FACTOR = 0.0
EPISODE_LENGTH = 32
LOG_STEP = 5


[ENV]
RATING_FILE = ratings.txt
ALPHA = 0.0
BOUNDARY_RATING = 3.5
MAX_RATING = 5.0
MIN_RATING = 0.0
POP1_ID = 104


[PRE_TRAIN]
PRE_TRAINING_STEP = 36
PRE_TRAINING_MASK_LENGTH = 32
PRE_TRAINING_SEQ_LENGTH = 32
PRE_TRAINING_RNN_TRUNCATED_LENGTH = 32

SAMPLE_EPISODE = 1
SAMPLE_USER = 4000

LEARNING_RATE = 1e-2
L2_FACTOR = 1e-5
ENTROPY_FACTOR = 1e0


[DQN]
SAMPLE_BATCH = 1000
UPDATE_BATCH = 10000
SAMPLE_TIMES = 1
UPDATE_TIMES = 10

MAX_EPSILON = 1.0
MIN_EPSILON = 0.1
DECAY_STEP = 160

HIDDEN_UNITS_1 = 128
BUFFER_SIZE = 200000
TAU = 0.99
LEARNING_RATE = 1e-3
L2_FACTOR =1e-6